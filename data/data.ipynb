{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as tr \n",
    "\n",
    "from dataset import make_dataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 512, 512])\n",
      "(tensor([4]), tensor([4]), tensor([4]), tensor([4]))\n",
      "(tensor([[ 200.9026,    0.0000, 1158.6770,  960.9201]]), tensor([[ 266.9031,  348.4540, 1536.1183,  878.4917]]), tensor([[ 897.0312,    0.0000, 1280.0000,  720.0000]]), tensor([[ 348.3173,  163.5216, 1481.7118,  965.0387]]))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from data.dataset import make_dataset, collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ÏÑ§Ï†ï Î≥ÄÏàò\n",
    "batch_size = 4\n",
    "size = 512\n",
    "\n",
    "image_dir_train = 'train/images/'\n",
    "bbox_dir_train = 'train/bbox/'\n",
    "\n",
    "image_dir_val = 'validation/images/'\n",
    "bbox_dir_val = 'validation/bbox/'\n",
    "\n",
    "image_dir_test = 'test/images/'\n",
    "bbox_dir_test = 'test/bbox/'\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±\n",
    "train_set = make_dataset(\n",
    "    image_dir=image_dir_train,\n",
    "    bbox_dir=bbox_dir_train\n",
    ")\n",
    "\n",
    "val_set = make_dataset(\n",
    "    image_dir=image_dir_val,\n",
    "    bbox_dir=bbox_dir_val\n",
    ")\n",
    "\n",
    "test_set = make_dataset(\n",
    "    image_dir=image_dir_test,\n",
    "    bbox_dir=bbox_dir_test\n",
    ")\n",
    "\n",
    "# DataLoader ÏÉùÏÑ±\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Ï∂úÎ†•\n",
    "images, labels, bbox = next(iter(val_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels)\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.2.28-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (3.8.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (0.17.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (5.9.8)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=0.2.5 (from ultralytics)\n",
      "  Downloading ultralytics_thop-0.2.7-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.99)\n",
      "Requirement already satisfied: six>=1.5 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/team1/anaconda3/envs/team1/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, ultralytics-thop, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 ultralytics-8.2.28 ultralytics-thop-0.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/team1/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  7 20:34:04 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp                Off | 00000000:19:00.0 Off |                  N/A |\n",
      "| 35%   59C    P2              83W / 250W |   2878MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN Xp                Off | 00000000:65:00.0 Off |                  N/A |\n",
      "| 44%   76C    P2             240W / 250W |   8860MiB / 12288MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1103      G   /usr/lib/xorg/Xorg                           16MiB |\n",
      "|    0   N/A  N/A      1228      G   /usr/bin/gnome-shell                          4MiB |\n",
      "|    0   N/A  N/A   2229567      C   ...am1/anaconda3/envs/team1/bin/python     2850MiB |\n",
      "|    1   N/A  N/A      1103      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A   2214077      C   /home/team2/anaconda3/bin/python           8852MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('DL_Programming/yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 80\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(type(model.names), len(model.names))\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 üöÄ Python-3.10.14 torch-2.2.1+cu121 CUDA:0 (NVIDIA TITAN Xp, 12188MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=DL_Programming/yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=10, batch=128, imgsz=512, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train9\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train9', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjitoo6611\u001b[0m (\u001b[33minteractive_ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/ddrive/team1/DL/DL_Programming/data/wandb/run-20240607_204557-i6jqrmby</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/interactive_ai/YOLOv8/runs/i6jqrmby' target=\"_blank\">train9</a></strong> to <a href='https://wandb.ai/interactive_ai/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/interactive_ai/YOLOv8' target=\"_blank\">https://wandb.ai/interactive_ai/YOLOv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/interactive_ai/YOLOv8/runs/i6jqrmby' target=\"_blank\">https://wandb.ai/interactive_ai/YOLOv8/runs/i6jqrmby</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/ddrive/team1/DL/DL_Programming/data/train/labels.cache... 8421 images, 0 backgrounds, 32 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8421/8421 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_009_00046.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0029]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_010_00326.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0011      1.0029]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_010_00359.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_042_01171.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0011]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_042_07627.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0011]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_042_08641.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0023]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_045_00639.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_045_03356.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_045_03487.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_045_03530.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_046_04100.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0011      1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/bundle of ropes_048_03584.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0023]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/circular fish trap_004_02328.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/fish net_004_00817.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/fish net_004_02354.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/fish net_004_03018.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/fish net_004_03545.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0005      1.0004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/fish net_004_04351.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/fish net_029_02342.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2064       1.279]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/rope_045_01626.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/rope_045_01663.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/rope_045_02420.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/spring fish trap_029_01799.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0011]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/spring fish trap_029_01907.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/spring fish trap_044_06201.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0007]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/tire_004_00418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/tire_045_00547.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/tire_045_02135.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0062]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/tire_045_03539.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/tire_045_04412.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0062]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/wood_047_03039.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/train/images/wood_048_04596.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/ddrive/team1/DL/DL_Programming/data/validation/labels.cache... 2406 images, 0 backgrounds, 4 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2406/2406 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/validation/images/bundle of ropes_045_02766.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/validation/images/fish net_004_01515.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/validation/images/spring fish trap_045_04682.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /mnt/ddrive/team1/DL/DL_Programming/data/validation/images/tire_042_09867.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train9/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train9\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50        12G      1.034      2.501      1.375        189        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [02:01<00:00,  1.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:15<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.478      0.332      0.365       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      11.8G      1.026      1.679      1.318        185        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:30<00:00,  1.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:15<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.445      0.326      0.312      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      11.8G      1.059      1.556       1.33        175        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:17<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:24<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.358      0.267      0.247      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      11.8G       1.06      1.435      1.326        168        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:17<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.633       0.52      0.525      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      11.8G       1.02      1.324      1.301        169        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:15<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:20<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.597       0.47      0.467      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      11.8G      0.988      1.265      1.281        169        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:21<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:19<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.685      0.361      0.417        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      11.8G      0.946      1.181      1.258        178        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:24<00:00,  1.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:19<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.625      0.508      0.528      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      11.8G     0.9391      1.173      1.252        179        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:16<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:43<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.645      0.566      0.566      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      11.8G     0.9102      1.104      1.232        173        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:51<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.614       0.44      0.441      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      11.8G     0.9005      1.113      1.233        178        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:41<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:27<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.663      0.562      0.577      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      11.8G      0.877      1.062      1.213        167        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:37<00:00,  1.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:32<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.732      0.588      0.634      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      11.8G     0.8679      1.038       1.21        187        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:46<00:00,  1.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:47<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.697      0.577      0.615      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      11.8G     0.8459      1.012      1.194        206        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [02:00<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:51<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.764      0.575      0.622      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      11.8G     0.8409      1.003      1.194        187        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [02:05<00:00,  1.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:51<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.737      0.582      0.617       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      11.8G     0.8327     0.9931      1.188        184        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [02:24<00:00,  2.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:46<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.729      0.659      0.671      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      11.8G     0.8169     0.9703      1.176        187        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [03:23<00:00,  3.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:44<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.723      0.628      0.649      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      11.8G     0.8094     0.9437      1.174        171        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [03:27<00:00,  3.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:39<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402      0.771      0.653      0.675      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      11.8G     0.7981     0.9156      1.165        159        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [02:11<00:00,  1.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:31<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2402       2402       0.77      0.648      0.675      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      11.8G     0.7955     0.9281      1.168        182        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [01:43<00:00,  1.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  10%|‚ñà         | 1/10 [00:01<00:10,  1.16s/it]"
     ]
    }
   ],
   "source": [
    "model.train(data='data.yaml', epochs=50, patience=10, batch=128, imgsz=512, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(model.names), len(model.names))\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source='data\\test\\images', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from typing import Type\n",
    "import torch\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, bbox_dir, transform):\n",
    "        self.image_dir = image_dir\n",
    "        self.bbox_dir = bbox_dir\n",
    "        self.data_images = [file for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
    "        self.transform = transform\n",
    "\n",
    "        # Î†àÏù¥Î∏î Îß§Ìïë ÎîïÏÖîÎÑàÎ¶¨\n",
    "        self.label_map = {\n",
    "            'tire': 0,\n",
    "            'spring fish trap': 1,\n",
    "            'circular fish trap': 1,\n",
    "            'rectangular fish trap': 1,\n",
    "            'eel fish trap': 1,\n",
    "            'fish net': 2,\n",
    "            'wood': 3,\n",
    "            'rope': 4,\n",
    "            'bundle of ropes': 4\n",
    "        }\n",
    "\n",
    "    def parse_bbox_xml(self, xml_file, image_width, image_height):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "            label = self.label_map.get(name, -1)  # Î†àÏù¥Î∏î Îß§Ìïë, ÏóÜÏúºÎ©¥ -1\n",
    "            \n",
    "            if label == -1:\n",
    "                continue\n",
    "\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = float(bbox.find('xmin').text) / image_width\n",
    "            ymin = float(bbox.find('ymin').text) / image_height\n",
    "            xmax = float(bbox.find('xmax').text) / image_width\n",
    "            ymax = float(bbox.find('ymax').text) / image_height\n",
    "\n",
    "            # Î∞îÏö¥Îî© Î∞ïÏä§Ïùò Ï§ëÏã¨Ï†êÍ≥º ÎÑàÎπÑ, ÎÜíÏù¥ Í≥ÑÏÇ∞\n",
    "            x_center = (xmin + xmax) / 2\n",
    "            y_center = (ymin + ymax) / 2\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "\n",
    "            boxes.append([x_center, y_center, width, height])\n",
    "            labels.append(label)\n",
    "\n",
    "        # Í∞ùÏ≤¥Í∞Ä 1Í∞úÎßå ÏûàÎäî Í≤ΩÏö∞Îßå Î∞òÌôò\n",
    "        if len(boxes) == 1 and len(labels) == 1:\n",
    "            return boxes, labels\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.data_images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_file)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        # xml ÌååÏùº Í≤ΩÎ°ú Ï∞æÍ∏∞\n",
    "        xml_file = os.path.join(self.bbox_dir, img_file.replace('.jpg', '.xml'))\n",
    "\n",
    "        boxes, labels = self.parse_bbox_xml(xml_file, image_width, image_height)\n",
    "        \n",
    "        # boxes ÎòêÎäî labelsÍ∞Ä NoneÏù¥Î©¥ Îã§Ïùå Îç∞Ïù¥ÌÑ∞Î°ú ÎÑòÏñ¥Í∞ê\n",
    "        if boxes is None or labels is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.data_images))\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, labels, boxes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_images)\n",
    "\n",
    "def make_dataset(image_dir: str,\n",
    "                 bbox_dir: str,\n",
    "                 transform=tr.Compose([tr.Resize((512, 512)), \n",
    "                                       tr.ToTensor(),                                       \n",
    "                                       tr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                       ])\n",
    "                 ) -> Type[torch.utils.data.Dataset]:\n",
    "    \"\"\"\n",
    "    Make pytorch Dataset for given task.\n",
    "    Read the image using the PIL library and return it as an np.array.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): dataset directory\n",
    "        bbox_dir (str) : dataset directory\n",
    "        transform (torchvision.transforms) pytorch image transforms  \n",
    "\n",
    "    Returns:\n",
    "        torch.Dataset: pytorch Dataset\n",
    "    \"\"\"\n",
    "        \n",
    "    dataset = CustomDataset(image_dir=image_dir,\n",
    "                            bbox_dir=bbox_dir,\n",
    "                            transform=transform)\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels, boxes = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    return images, labels, boxes\n",
    "\n",
    "# Ï†ÄÏû•Ìï† Í≤ΩÎ°ú\n",
    "image_dir_train = 'train/images/'\n",
    "bbox_dir_train = 'train/bbox/'\n",
    "\n",
    "image_dir_val = 'validation/images/'\n",
    "bbox_dir_val = 'validation/bbox/'\n",
    "\n",
    "image_dir_test = 'test/images/'\n",
    "bbox_dir_test = 'test/bbox/'\n",
    "\n",
    "# ÎùºÎ≤® ÌååÏùº ÏÉùÏÑ± Î∞è Ï†ÄÏû•\n",
    "def save_label_file(image_file, labels, boxes, output_dir):\n",
    "    label_file = image_file.replace('.jpg', '.txt')\n",
    "    with open(os.path.join(output_dir, label_file), 'w') as f:\n",
    "        for label, box in zip(labels, boxes):\n",
    "            x_center, y_center, width, height = box\n",
    "            line = f\"{label} {x_center} {y_center} {width} {height}\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "def save_label_files(dataset, image_dir, bbox_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for idx in range(len(dataset)):\n",
    "        image, labels, boxes = dataset[idx]\n",
    "        image_file = dataset.data_images[idx]\n",
    "        save_label_file(image_file, labels, boxes, output_dir)\n",
    "\n",
    "# train set\n",
    "train_dataset = make_dataset(image_dir_train, bbox_dir_train)\n",
    "save_label_files(train_dataset, image_dir_train, bbox_dir_train, 'train/labels')\n",
    "\n",
    "# validation set\n",
    "val_dataset = make_dataset(image_dir_val, bbox_dir_val)\n",
    "save_label_files(val_dataset, image_dir_val, bbox_dir_val, 'validation/labels')\n",
    "\n",
    "# test set\n",
    "# test_dataset = make_dataset(image_dir_test, bbox_dir_test)\n",
    "# save_label_files(test_dataset, image_dir_test, bbox_dir_test, 'test/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def read_yolo_label(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        class_id, x_center, y_center, width, height = map(float, parts)\n",
    "        labels.append((int(class_id), x_center, y_center, width, height))\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def draw_bounding_boxes(image, labels):\n",
    "    h, w, _ = image.shape\n",
    "    for class_id, x_center, y_center, width, height in labels:\n",
    "        x_min = int((x_center - width/2) * w)\n",
    "        y_min = int((y_center - height/2) * h)\n",
    "        x_max = int((x_center + width/2) * w)\n",
    "        y_max = int((y_center + height/2) * h)\n",
    "        \n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'Class: {class_id}', (x_min, y_min - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ Î∞è Î†àÏù¥Î∏î ÌååÏùº Í≤ΩÎ°ú\n",
    "image_path = 'test/images/wood_048_04863.jpg'\n",
    "label_file = 'test/labels/wood_048_04863.txt'\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ ÏùΩÍ∏∞\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(f\"Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§: {image_path}\")\n",
    "    exit()\n",
    "\n",
    "# Î†àÏù¥Î∏î ÏùΩÍ∏∞\n",
    "labels = read_yolo_label(label_file)\n",
    "\n",
    "# Bounding box Í∑∏Î¶¨Í∏∞\n",
    "image_with_boxes = draw_bounding_boxes(image.copy(), labels)\n",
    "\n",
    "# Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄ ÌëúÏãú\n",
    "cv2.imshow('Image with Bounding Boxes', image_with_boxes)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
