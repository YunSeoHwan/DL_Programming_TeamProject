{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 로드\n",
    "import os\n",
    "from data_loading import load_images_and_annotations\n",
    "from data_processing import convert_annotations\n",
    "from prepare_dataset import prepare_dataset, create_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing training data...\n",
      "Loading images and annotations from C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\train\\images and C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\train\\bbox\n",
      "Loaded 8421 images and 8421 annotations.\n",
      "Loading and processing validation data...\n",
      "Loading images and annotations from C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\validation\\images and C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\validation\\bbox\n",
      "Loaded 2406 images and 2406 annotations.\n",
      "Loading and processing test data...\n",
      "Loading images and annotations from C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\test\\images and C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\test\\bbox\n",
      "Loaded 1203 images and 1203 annotations.\n",
      "Converting annotations...\n",
      "Converting annotations to new class labels...\n",
      "Converted 12030 annotations.\n",
      "Preparing dataset...\n",
      "Dataset prepared with 9624 training and 2406 validation images.\n",
      "YAML file created at C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로 설정\n",
    "path_to_training_images = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\train\\images'\n",
    "path_to_training_annotations = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\train\\bbox'\n",
    "path_to_validation_images = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\validation\\images'\n",
    "path_to_validation_annotations = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\validation\\bbox'\n",
    "path_to_test_images = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\test\\images'\n",
    "path_to_test_annotations = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\test\\bbox'\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "print(\"Loading and processing training data...\")\n",
    "train_images, train_annotations = load_images_and_annotations(path_to_training_images, path_to_training_annotations)\n",
    "print(\"Loading and processing validation data...\")\n",
    "val_images, val_annotations = load_images_and_annotations(path_to_validation_images, path_to_validation_annotations)\n",
    "print(\"Loading and processing test data...\")\n",
    "test_images, test_annotations = load_images_and_annotations(path_to_test_images, path_to_test_annotations)\n",
    "\n",
    "all_annotations = train_annotations + val_annotations + test_annotations\n",
    "print(\"Converting annotations...\")\n",
    "converted_annotations = convert_annotations(all_annotations)\n",
    "\n",
    "# 데이터셋 준비\n",
    "output_dir = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset'\n",
    "print(\"Preparing dataset...\")\n",
    "prepare_dataset(train_images + val_images + test_images, converted_annotations, output_dir)\n",
    "\n",
    "# 클래스 레이블 정의\n",
    "classes = ['타이어', '통발류', '어망류', '나무', '로프']\n",
    "create_yaml(output_dir, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 설치\n",
    "# !pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_images = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\train\\images'\n",
    "path_to_training_annotations = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\train\\bbox'\n",
    "path_to_validation_images = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\validation\\images'\n",
    "path_to_validation_annotations = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\validation\\bbox'\n",
    "path_to_test_images = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\test\\images'\n",
    "path_to_test_annotations = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\data\\test\\bbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is set to: C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset\n",
      "Model weights will be saved to: C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset\\weights\n",
      "Starting YOLOv8 training...\n",
      "Ultralytics YOLOv8.2.28  Python-3.11.7 torch-2.3.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\dhshs\\Documents\\   \\YOLOv8_dataset\\data.yaml, epochs=50, time=None, patience=5, batch=32, imgsz=256, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=yolo_underwater_trash16, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\dhshs\\Documents\\CCTV\\ultralytics\\runs\\detect\\yolo_underwater_trash16\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir c:\\Users\\dhshs\\Documents\\CCTV\\ultralytics\\runs\\detect\\yolo_underwater_trash16', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset\\train\\labels.cache... 0 images, 9624 backgrounds, 0 corrupt: 100%|██████████| 9624/9624 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  No labels found in C:\\Users\\dhshs\\Documents\\   \\YOLOv8_dataset\\train\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset\\val\\labels.cache... 0 images, 2406 backgrounds, 0 corrupt: 100%|██████████| 2406/2406 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  No labels found in C:\\Users\\dhshs\\Documents\\   \\YOLOv8_dataset\\val\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to c:\\Users\\dhshs\\Documents\\CCTV\\ultralytics\\runs\\detect\\yolo_underwater_trash16\\labels.jpg... \n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 256 train, 256 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\dhshs\\Documents\\CCTV\\ultralytics\\runs\\detect\\yolo_underwater_trash16\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G          0      41.28          0          0        256:   1%|          | 3/301 [00:10<17:04,  3.44s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# output_dir 변수 정의 확인\n",
    "output_dir = r'C:\\Users\\dhshs\\Documents\\해양 침적 쓰레기 이미지\\YOLOv8_dataset'\n",
    "print(f\"Output directory is set to: {output_dir}\")\n",
    "\n",
    "# 모델 가중치를 저장할 디렉토리 생성\n",
    "weights_dir = os.path.join(output_dir, 'weights')\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "print(f\"Model weights will be saved to: {weights_dir}\")\n",
    "\n",
    "# YOLOv8 학습 실행\n",
    "print(\"Starting YOLOv8 training...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# 성능 지표 저장용 리스트 초기화\n",
    "epoch_metrics = []\n",
    "\n",
    "# Early Stopping을 적용하고 학습 모니터링\n",
    "results = model.train(\n",
    "    data=os.path.join(output_dir, 'data.yaml'),\n",
    "    epochs=50,\n",
    "    imgsz=256,\n",
    "    batch=32,\n",
    "    name=\"yolo_underwater_trash\",\n",
    "    patience=5,  # Early stopping을 위해 5 epochs 동안 성능 향상이 없으면 중지\n",
    "    device='cpu'  # CPU로 학습 강제\n",
    ")\n",
    "\n",
    "# 매 에포크마다 가중치 저장 및 성능 평가\n",
    "for epoch in range(50):\n",
    "    weight_path = os.path.join(weights_dir, f'epoch_{epoch + 1}.pt')\n",
    "    model.save(weight_path)\n",
    "    print(f\"Weights saved to {weight_path} after epoch {epoch + 1}\")\n",
    "\n",
    "    # 모델 평가\n",
    "    results = model.val(data=os.path.join(output_dir, 'data.yaml'), split='test')\n",
    "    metrics = results.metrics\n",
    "    epoch_metrics.append(metrics)\n",
    "\n",
    "# 성능 지표 시각화\n",
    "epochs = list(range(1, 51))\n",
    "precision = [metrics['precision'] for metrics in epoch_metrics]\n",
    "recall = [metrics['recall'] for metrics in epoch_metrics]\n",
    "mAP_50 = [metrics['map50'] for metrics in epoch_metrics]\n",
    "mAP_95 = [metrics['map'] for metrics in epoch_metrics]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, precision, label='Precision')\n",
    "plt.plot(epochs, recall, label='Recall')\n",
    "plt.plot(epochs, mAP_50, label='mAP@0.5')\n",
    "plt.plot(epochs, mAP_95, label='mAP@0.5:0.95')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Model Performance on Test Dataset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 특정 에포크 번호 설정\n",
    "epoch_number = 1  # 평가할 에포크 번호를 설정\n",
    "\n",
    "# 저장된 가중치 파일 경로 설정\n",
    "weight_path = os.path.join(weights_dir, f'epoch_{epoch_number}.pt')\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(weight_path)\n",
    "\n",
    "# 테스트 데이터셋을 사용하여 모델 평가\n",
    "results = model.val(data=os.path.join(output_dir, 'data.yaml'), split='test')\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(f\"Evaluation results for epoch {epoch_number}:\")\n",
    "print(f\"Precision: {results.metrics['precision']}\")\n",
    "print(f\"Recall: {results.metrics['recall']}\")\n",
    "print(f\"mAP@0.5: {results.metrics['map50']}\")\n",
    "print(f\"mAP@0.5:0.95: {results.metrics['map']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
